{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T07:05:09.515826Z",
     "iopub.status.busy": "2025-11-26T07:05:09.515351Z",
     "iopub.status.idle": "2025-11-26T07:05:12.607930Z",
     "shell.execute_reply": "2025-11-26T07:05:12.606575Z",
     "shell.execute_reply.started": "2025-11-26T07:05:09.515790Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "test_df = pd.read_csv('test_updated.csv')\n",
    "train_df = pd.read_csv('train_updated.csv')\n",
    "\n",
    "target = train_df['RiskFlag']\n",
    "train_ids = train_df['ProfileID']\n",
    "test_ids = test_df['ProfileID']\n",
    "\n",
    "train_features = train_df.drop(columns=['RiskFlag', 'ProfileID'])\n",
    "test_features = test_df.drop(columns=['ProfileID'])\n",
    "\n",
    "combined_df = pd.concat([train_features, test_features], axis=0)\n",
    "\n",
    "# Encoding \n",
    "education_map = {\"High School\": 0, \"Bachelor's\": 1, \"Master's\": 2, \"PhD\": 3}\n",
    "combined_df['QualificationLevel'] = combined_df['QualificationLevel'].map(education_map)\n",
    "\n",
    "binary_map = {'Yes': 1, 'No': 0}\n",
    "for col in ['OwnsProperty', 'FamilyObligation', 'JointApplicant']:\n",
    "    combined_df[col] = combined_df[col].map(binary_map)\n",
    "\n",
    "\n",
    "# Feature Engineering\n",
    "\n",
    "# Financial ratios\n",
    "combined_df['Loan_to_Income'] = combined_df['RequestedSum'] / combined_df['AnnualEarnings']\n",
    "combined_df['EMI_Approx'] = combined_df['RequestedSum'] / combined_df['RepayPeriod']\n",
    "combined_df['EMI_to_Income'] = combined_df['EMI_Approx'] / (combined_df['AnnualEarnings'] / 12)\n",
    "combined_df['Debt_to_Loan'] = combined_df['DebtFactor'] / (combined_df['RequestedSum'] + 1e-6)\n",
    "combined_df['Earnings_per_Account'] = combined_df['AnnualEarnings'] / (combined_df['ActiveAccounts'] + 1e-6)\n",
    "combined_df['MonthlyIncome'] = combined_df['AnnualEarnings'] / 12\n",
    "combined_df['Repayment_to_Earnings'] = combined_df['RequestedSum'] / (combined_df['AnnualEarnings'] * combined_df['RepayPeriod'] / 12 + 1e-6)\n",
    "combined_df['Margin_after_Debt'] = combined_df['MonthlyIncome'] - (combined_df['DebtFactor'] * combined_df['MonthlyIncome'])\n",
    "\n",
    "# Interaction features\n",
    "combined_df['Trust_Qualification'] = combined_df['TrustMetric'] * combined_df['QualificationLevel']\n",
    "combined_df['WorkDuration_Qualification'] = combined_df['WorkDuration'] * combined_df['QualificationLevel']\n",
    "\n",
    "# Temporal and count features\n",
    "combined_df['Log_WorkDuration'] = np.log1p(combined_df['WorkDuration'])\n",
    "combined_df['Log_ActiveAccounts'] = np.log1p(combined_df['ActiveAccounts'])\n",
    "combined_df['WorkDuration_Bin'] = pd.cut(combined_df['WorkDuration'], bins=[-np.inf, 12, 60, np.inf], labels=[0,1,2])\n",
    "\n",
    "# Age group bins: 18-30 young, 31-50 mid, 50+ senior\n",
    "combined_df['Age_Group'] = pd.cut(combined_df['ApplicantYears'], bins=[0,30,50,np.inf], labels=[0,1,2])\n",
    "\n",
    "# Property and JointApplicant interaction\n",
    "combined_df['Property_JointApplicant'] = combined_df['OwnsProperty'] * combined_df['JointApplicant']\n",
    "\n",
    "combined_df = pd.get_dummies(combined_df, columns=['WorkDuration_Bin', 'Age_Group'], drop_first=True)\n",
    "\n",
    "for col in ['AnnualEarnings', 'RequestedSum']:\n",
    "    combined_df[col] = np.log1p(combined_df[col])\n",
    "\n",
    "\n",
    "combined_df = pd.get_dummies(combined_df, columns=['WorkCategory', 'RelationshipStatus', 'FundUseCase'], drop_first=True)\n",
    "\n",
    "# Scaling\n",
    "numeric_cols = combined_df.select_dtypes(include=['int64', 'float64']).columns\n",
    "scaler = StandardScaler()\n",
    "combined_df[numeric_cols] = scaler.fit_transform(combined_df[numeric_cols])\n",
    "\n",
    "# Polynomial Features \n",
    "# poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "# combined_poly = poly.fit_transform(combined_df)\n",
    "\n",
    "X = combined_df[:len(train_df)]\n",
    "X_test_submission = combined_df[len(train_df):]\n",
    "y = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T07:05:12.609419Z",
     "iopub.status.busy": "2025-11-26T07:05:12.609072Z",
     "iopub.status.idle": "2025-11-26T07:05:15.790161Z",
     "shell.execute_reply": "2025-11-26T07:05:15.788803Z",
     "shell.execute_reply.started": "2025-11-26T07:05:12.609387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     36105\n",
      "           1       0.64      0.06      0.11      4751\n",
      "\n",
      "    accuracy                           0.89     40856\n",
      "   macro avg       0.76      0.53      0.52     40856\n",
      "weighted avg       0.86      0.89      0.84     40856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "log_reg = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_proba = log_reg.predict_proba(X_val)[:, 1]\n",
    "\n",
    "#0.5 with basic pre-processing gave bad score on test data\n",
    "#0.65 gave 0.82\n",
    "#0.8 gave 0.881\n",
    "#0.85 gave 0.886\n",
    "threshold = 0.9  # Tuned threshold\n",
    "y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "test_probs = log_reg.predict_proba(X_test_submission)[:, 1]\n",
    "test_predictions = (test_probs >= threshold).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({'ProfileID': test_ids, 'RiskFlag': test_predictions})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Threshold: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.69      0.80     36105\n",
      "           1       0.23      0.70      0.34      4751\n",
      "\n",
      "    accuracy                           0.69     40856\n",
      "   macro avg       0.59      0.69      0.57     40856\n",
      "weighted avg       0.86      0.69      0.74     40856\n",
      "\n",
      "\n",
      "Threshold: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.82      0.87     36105\n",
      "           1       0.28      0.54      0.37      4751\n",
      "\n",
      "    accuracy                           0.79     40856\n",
      "   macro avg       0.61      0.68      0.62     40856\n",
      "weighted avg       0.86      0.79      0.81     40856\n",
      "\n",
      "\n",
      "Threshold: 0.7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91     36105\n",
      "           1       0.35      0.36      0.35      4751\n",
      "\n",
      "    accuracy                           0.85     40856\n",
      "   macro avg       0.63      0.63      0.63     40856\n",
      "weighted avg       0.85      0.85      0.85     40856\n",
      "\n",
      "\n",
      "Threshold: 0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93     36105\n",
      "           1       0.40      0.27      0.32      4751\n",
      "\n",
      "    accuracy                           0.87     40856\n",
      "   macro avg       0.65      0.61      0.62     40856\n",
      "weighted avg       0.85      0.87      0.86     40856\n",
      "\n",
      "\n",
      "Threshold: 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93     36105\n",
      "           1       0.47      0.19      0.27      4751\n",
      "\n",
      "    accuracy                           0.88     40856\n",
      "   macro avg       0.68      0.58      0.60     40856\n",
      "weighted avg       0.85      0.88      0.86     40856\n",
      "\n",
      "\n",
      "Threshold: 0.85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94     36105\n",
      "           1       0.53      0.11      0.19      4751\n",
      "\n",
      "    accuracy                           0.89     40856\n",
      "   macro avg       0.71      0.55      0.56     40856\n",
      "weighted avg       0.85      0.89      0.85     40856\n",
      "\n",
      "\n",
      "Threshold: 0.9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     36105\n",
      "           1       0.64      0.06      0.11      4751\n",
      "\n",
      "    accuracy                           0.89     40856\n",
      "   macro avg       0.76      0.53      0.52     40856\n",
      "weighted avg       0.86      0.89      0.84     40856\n",
      "\n",
      "\n",
      "Threshold: 0.92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     36105\n",
      "           1       0.70      0.04      0.08      4751\n",
      "\n",
      "    accuracy                           0.89     40856\n",
      "   macro avg       0.79      0.52      0.51     40856\n",
      "weighted avg       0.87      0.89      0.84     40856\n",
      "\n",
      "\n",
      "Threshold: 0.95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     36105\n",
      "           1       0.78      0.02      0.03      4751\n",
      "\n",
      "    accuracy                           0.89     40856\n",
      "   macro avg       0.83      0.51      0.49     40856\n",
      "weighted avg       0.87      0.89      0.83     40856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking accuracy on different thresholds\n",
    "thresholds = [0.5, 0.6, 0.7, 0.75, 0.80, 0.85, 0.90, 0.92, 0.95]\n",
    "for thr in thresholds:\n",
    "    y_val_pred = (y_proba >= thr).astype(int)\n",
    "    print(f\"\\nThreshold: {thr}\")\n",
    "    print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_regression_model_nb.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(log_reg, \"logistic_regression_model_nb.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8866996279616213\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     36105\n",
      "           1       0.64      0.06      0.11      4751\n",
      "\n",
      "    accuracy                           0.89     40856\n",
      "   macro avg       0.76      0.53      0.52     40856\n",
      "weighted avg       0.86      0.89      0.84     40856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "model = joblib.load(\"logistic_regression_model_nb.pkl\") \n",
    "\n",
    "y_proba = model.predict_proba(X_val)[:, 1]\n",
    "y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14434066,
     "sourceId": 120679,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
